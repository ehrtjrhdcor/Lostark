#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import sys
import json
from paddleocr import PaddleOCR
import cv2
import numpy as np
from PIL import Image
import re

def preprocess_image(image_path):
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ - ê²Œì„ UI í…ìŠ¤íŠ¸ ì¸ì‹ë¥  í–¥ìƒ (í”¼í•´ëŸ‰ íŠ¹í™”)"""
    # ì´ë¯¸ì§€ ì½ê¸°
    image = cv2.imread(image_path)
    
    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # 1. ëŒ€ë¹„ ê°•í™” (ë” ê°•í•˜ê²Œ)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
    enhanced = clahe.apply(gray)
    
    # 2. ê°ë§ˆ ë³´ì • (ë°ì€ í…ìŠ¤íŠ¸ ê°•ì¡°)
    gamma = 1.5
    invGamma = 1.0 / gamma
    table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
    gamma_corrected = cv2.LUT(enhanced, table)
    
    # 3. ìƒ¤í”„ë‹ (í…ìŠ¤íŠ¸ ê²½ê³„ ëª…í™•í™”)
    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
    sharpened = cv2.filter2D(gamma_corrected, -1, kernel)
    
    # 4. ëª¨í´ë¡œì§€ ì—°ì‚° (í…ìŠ¤íŠ¸ ì—°ê²°ì„± í–¥ìƒ)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 1))
    morphed = cv2.morphologyEx(sharpened, cv2.MORPH_CLOSE, kernel)
    
    # 5. ë…¸ì´ì¦ˆ ì œê±° (ì•½í•˜ê²Œ)
    denoised = cv2.bilateralFilter(morphed, 5, 50, 50)
    
    # 6. ì´ì§„í™” (ì„ê³„ê°’ ì ì‘ì )
    binary = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
    
    return binary

def parse_lostark_data(ocr_results):
    """ë¡œìŠ¤íŠ¸ì•„í¬ ê¸¸ë“œ ì •ë³´ íŒŒì‹± - ê°œì„ ëœ ë²„ì „"""
    all_text = []
    high_confidence_text = []
    
    for (bbox, text, confidence) in ocr_results:
        if confidence > 0.3:  # ì‹ ë¢°ë„ 30% ì´ìƒ
            all_text.append(text)
            if confidence > 0.7:  # ë†’ì€ ì‹ ë¢°ë„ í…ìŠ¤íŠ¸ ë³„ë„ ì €ì¥
                high_confidence_text.append(text)
    
    # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
    full_text = ' '.join(all_text)
    
    # ë¡œìŠ¤íŠ¸ì•„í¬ ê¸¸ë“œ í†µê³„ íŒ¨í„´ (ì´ë¯¸ì§€ ê¸°ë°˜)
    stat_patterns = {
        # ì£¼ìš” ì •ë³´
        'ì „íˆ¬ ì‹œê°„': [
            r'ì „íˆ¬.*?ì‹œê°„[^\d]*(\d+:\d+)',
            r'(\d+:\d+).*ì „íˆ¬',
            r'(\d+ë¶„\s*\d+ì´ˆ)',
            r'(\d{1,2}:\d{2})'
        ],
        'í”¼í•´ëŸ‰': [
            r'í”¼í•´ëŸ‰[^\d]*(\d+[,.]?\d*\.?\d*ì–µ)',
            r'(\d+[,.]?\d*\.?\d*ì–µ).*?\n.*í”¼í•´ëŸ‰',
            r'(\d{1,3},\d{3},\d{3},\d{3})',  # í° ìˆ«ì
            r'(\d+\.?\d*ì–µ)'
        ],
        'ì´ˆë‹¹ í”¼í•´ëŸ‰': [
            r'ì´ˆë‹¹.*?í”¼í•´ëŸ‰[^\d]*(\d+[,.]?\d*\.?\d*ì–µ)',
            r'ì´ˆë‹¹.*?(\d+[,.]?\d*\.?\d*ì–µ)',
            r'(\d+\.?\d*ì–µ).*ì´ˆë‹¹',
            r'ì´ˆë‹¹.*?(\d{1,3},\d{3},\d{3})'
        ],
        '1ë¶„ í”¼í•´ëŸ‰': [
            r'1ë¶„.*?í”¼í•´ëŸ‰[^\d]*(\d+[,.]?\d*\.?\d*ì–µ)',
            r'1ë¶„.*?(\d+[,.]?\d*\.?\d*ì–µ)',
            r'(\d+\.?\d*ì–µ).*1ë¶„'
        ],
        # ì¶”ê°€ ì •ë³´
        'ì¹˜ëª…íƒ€ ì ì¤‘ë¥ ': [
            r'ì¹˜ëª…íƒ€.*?ì ì¤‘ë¥ [^\d]*(\d+\.?\d*%)',
            r'ì¹˜ëª…íƒ€.*?(\d+\.?\d*%)',
            r'(\d+\.?\d*%).*ì¹˜ëª…íƒ€'
        ],
        'ë°±ì–´íƒ ì ì¤‘ë¥ ': [
            r'ë°±ì–´íƒ.*?ì ì¤‘ë¥ [^\d]*(\d+\.?\d*%)',
            r'ë°±ì–´íƒ.*?(\d+\.?\d*%)',
            r'(\d+\.?\d*%).*ë°±ì–´íƒ'
        ],
        'í—¤ë“œì–´íƒ ì ì¤‘ë¥ ': [
            r'í—¤ë“œì–´íƒ.*?ì ì¤‘ë¥ [^\d]*(\d+\.?\d*%)',
            r'í—¤ë“œì–´íƒ.*?(\d+\.?\d*%)',
            r'(\d+\.?\d*%).*í—¤ë“œì–´íƒ'
        ],
        'ë°›ì€ í”¼í•´ëŸ‰': [
            r'ë°›ì€.*?í”¼í•´ëŸ‰[^\d]*(\d+[,.]?\d*\.?\d*ë§Œ)',
            r'ë°›ì€.*?(\d+[,.]?\d*\.?\d*ë§Œ)',
            r'(\d+\.?\d*ë§Œ).*ë°›ì€'
        ],
        'ë¬´ë ¥í™”': [
            r'ë¬´ë ¥í™”[^\d]*(\d+[,.]?\d*)',
            r'(\d+[,.]?\d*).*ë¬´ë ¥í™”',
            r'(\d+,\d{3})'
        ],
        'ì¹´ìš´í„° ì„±ê³µ': [
            r'ì¹´ìš´í„°.*?ì„±ê³µ[^\d]*(\d+)',
            r'ì¹´ìš´í„°.*?(\d+)',
            r'(\d+).*ì¹´ìš´í„°'
        ],
        'ì €ìŠ¤íŠ¸ ê°€ë“œ ì„±ê³µ íšŸìˆ˜': [
            r'ì €ìŠ¤íŠ¸.*?ê°€ë“œ.*?ì„±ê³µ.*?íšŸìˆ˜[^\d]*(\d+)',
            r'ì €ìŠ¤íŠ¸.*?ê°€ë“œ[^\d]*(\d+)',
            r'(\d+).*ì €ìŠ¤íŠ¸'
        ],
        'ë°°í‹€ ì•„ì´í…œ ì‚¬ìš© íšŸìˆ˜': [
            r'ë°°í‹€.*?ì•„ì´í…œ.*?ì‚¬ìš©.*?íšŸìˆ˜[^\d]*(\d+)',
            r'ì•„ì´í…œ.*?ì‚¬ìš©[^\d]*(\d+)',
            r'(\d+).*ì•„ì´í…œ'
        ],
        'ì§€ë‹¹íƒ€ ììƒ ê°ì†Œ ê°€ë™ë¥ ': [
            r'ì§€ë‹¹íƒ€.*?ììƒ.*?ê°ì†Œ.*?ê°€ë™ë¥ [^\d]*(\d+\.?\d*%)',
            r'ì§€ë‹¹íƒ€.*?(\d+\.?\d*%)',
            r'(\d+\.?\d*%).*ì§€ë‹¹íƒ€'
        ],
        'êµ¬ìŠ¬ì˜ ì¶•ë³µ ìœ íš¨ìœ¨': [
            r'êµ¬ìŠ¬.*?ì¶•ë³µ.*?ìœ íš¨ìœ¨[^\d]*(\d+\.?\d*%)',
            r'êµ¬ìŠ¬.*?ì¶•ë³µ.*?(\d+\.?\d*%)',
            r'(\d+\.?\d*%).*êµ¬ìŠ¬'
        ]
    }
    
    parsed_data = {
        'raw_text': all_text,
        'full_text': full_text,
        'high_confidence_text': high_confidence_text,
        'parsed_stats': {}
    }
    
    # í–¥ìƒëœ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œ
    for key, patterns in stat_patterns.items():
        for pattern in patterns:
            match = re.search(pattern, full_text, re.IGNORECASE)
            if match:
                parsed_data['parsed_stats'][key] = match.group(1)
                break  # ì²« ë²ˆì§¸ ë§¤ì¹˜ë¥¼ ì°¾ìœ¼ë©´ ë‹¤ìŒ íŒ¨í„´ìœ¼ë¡œ
    
    # ìˆ«ìë§Œ ìˆëŠ” í° ê°’ë“¤ë„ ì¶”ì¶œ (ê¸¸ë“œ í†µê³„ì—ì„œ ìì£¼ ë³´ì´ëŠ” íŒ¨í„´)
    large_numbers = re.findall(r'(\d{1,3}(?:,\d{3})*(?:\.\d+)?ì–µ?)', full_text)
    if large_numbers:
        parsed_data['large_numbers'] = large_numbers[:10]  # ìƒìœ„ 10ê°œë§Œ
    
    return parsed_data

def format_as_table(parsed_data):
    """ë¶„ì„ ê²°ê³¼ë¥¼ í‘œ í˜•íƒœë¡œ í¬ë§·íŒ…"""
    stats = parsed_data.get('parsed_stats', {})
    
    # ì£¼ìš” ì •ë³´ì™€ ì¶”ê°€ ì •ë³´ ë¶„ë¦¬
    main_info = {
        'ì „íˆ¬ ì‹œê°„': stats.get('ì „íˆ¬ ì‹œê°„', 'ë¯¸ì¸ì‹'),
        'í”¼í•´ëŸ‰': stats.get('í”¼í•´ëŸ‰', 'ë¯¸ì¸ì‹'),
        'ì´ˆë‹¹ í”¼í•´ëŸ‰': stats.get('ì´ˆë‹¹ í”¼í•´ëŸ‰', 'ë¯¸ì¸ì‹'),
        '1ë¶„ í”¼í•´ëŸ‰': stats.get('1ë¶„ í”¼í•´ëŸ‰', 'ë¯¸ì¸ì‹')
    }
    
    additional_info = {
        'ì¹˜ëª…íƒ€ ì ì¤‘ë¥ ': stats.get('ì¹˜ëª…íƒ€ ì ì¤‘ë¥ ', 'ë¯¸ì¸ì‹'),
        'ë°±ì–´íƒ ì ì¤‘ë¥ ': stats.get('ë°±ì–´íƒ ì ì¤‘ë¥ ', 'ë¯¸ì¸ì‹'), 
        'í—¤ë“œì–´íƒ ì ì¤‘ë¥ ': stats.get('í—¤ë“œì–´íƒ ì ì¤‘ë¥ ', 'ë¯¸ì¸ì‹'),
        'ë°›ì€ í”¼í•´ëŸ‰': stats.get('ë°›ì€ í”¼í•´ëŸ‰', 'ë¯¸ì¸ì‹'),
        'ë¬´ë ¥í™”': stats.get('ë¬´ë ¥í™”', 'ë¯¸ì¸ì‹'),
        'ì¹´ìš´í„° ì„±ê³µ': stats.get('ì¹´ìš´í„° ì„±ê³µ', 'ë¯¸ì¸ì‹'),
        'ì €ìŠ¤íŠ¸ ê°€ë“œ ì„±ê³µ íšŸìˆ˜': stats.get('ì €ìŠ¤íŠ¸ ê°€ë“œ ì„±ê³µ íšŸìˆ˜', 'ë¯¸ì¸ì‹'),
        'ë°°í‹€ ì•„ì´í…œ ì‚¬ìš© íšŸìˆ˜': stats.get('ë°°í‹€ ì•„ì´í…œ ì‚¬ìš© íšŸìˆ˜', 'ë¯¸ì¸ì‹'),
    }
    
    # í‘œ ìƒì„±
    table_output = []
    table_output.append("=" * 60)
    table_output.append("ğŸ¹ ë¡œìŠ¤íŠ¸ì•„í¬ ê¸¸ë“œ í†µê³„ ë¶„ì„ ê²°ê³¼")
    table_output.append("=" * 60)
    
    # ì£¼ìš” ì •ë³´ í‘œ
    table_output.append("\nğŸ“Š ì£¼ìš” ì •ë³´")
    table_output.append("-" * 40)
    for key, value in main_info.items():
        table_output.append(f"{key:<15} : {value}")
    
    # ì¶”ê°€ ì •ë³´ í‘œ
    table_output.append("\nğŸ“ˆ ì¶”ê°€ ì •ë³´")
    table_output.append("-" * 40)
    for key, value in additional_info.items():
        if value != 'ë¯¸ì¸ì‹':  # ì¸ì‹ëœ ê²ƒë§Œ í‘œì‹œ
            table_output.append(f"{key:<20} : {value}")
    
    # ì›ë³¸ í…ìŠ¤íŠ¸ (ë””ë²„ê¹…ìš©)
    if parsed_data.get('high_confidence_text'):
        table_output.append("\nğŸ” ê³ ì‹ ë¢°ë„ ì¸ì‹ í…ìŠ¤íŠ¸")
        table_output.append("-" * 40)
        for text in parsed_data['high_confidence_text'][:10]:  # ìƒìœ„ 10ê°œë§Œ
            table_output.append(f"â€¢ {text}")
    
    table_output.append("=" * 60)
    
    return "\n".join(table_output)

def format_as_table_html(parsed_data):
    """ë¶„ì„ ê²°ê³¼ë¥¼ HTML í‘œ í˜•íƒœë¡œ í¬ë§·íŒ…"""
    stats = parsed_data.get('parsed_stats', {})
    
    # ì£¼ìš” ì •ë³´ì™€ ì¶”ê°€ ì •ë³´ ë¶„ë¦¬
    main_info = {
        'ì „íˆ¬ ì‹œê°„': stats.get('ì „íˆ¬ ì‹œê°„', 'ë¯¸ì¸ì‹'),
        'í”¼í•´ëŸ‰': stats.get('í”¼í•´ëŸ‰', 'ë¯¸ì¸ì‹'),
        'ì´ˆë‹¹ í”¼í•´ëŸ‰': stats.get('ì´ˆë‹¹ í”¼í•´ëŸ‰', 'ë¯¸ì¸ì‹'),
        '1ë¶„ í”¼í•´ëŸ‰': stats.get('1ë¶„ í”¼í•´ëŸ‰', 'ë¯¸ì¸ì‹')
    }
    
    additional_info = {
        'ì¹˜ëª…íƒ€ ì ì¤‘ë¥ ': stats.get('ì¹˜ëª…íƒ€ ì ì¤‘ë¥ ', 'ë¯¸ì¸ì‹'),
        'ë°±ì–´íƒ ì ì¤‘ë¥ ': stats.get('ë°±ì–´íƒ ì ì¤‘ë¥ ', 'ë¯¸ì¸ì‹'), 
        'í—¤ë“œì–´íƒ ì ì¤‘ë¥ ': stats.get('í—¤ë“œì–´íƒ ì ì¤‘ë¥ ', 'ë¯¸ì¸ì‹'),
        'ë°›ì€ í”¼í•´ëŸ‰': stats.get('ë°›ì€ í”¼í•´ëŸ‰', 'ë¯¸ì¸ì‹'),
        'ë¬´ë ¥í™”': stats.get('ë¬´ë ¥í™”', 'ë¯¸ì¸ì‹'),
        'ì¹´ìš´í„° ì„±ê³µ': stats.get('ì¹´ìš´í„° ì„±ê³µ', 'ë¯¸ì¸ì‹'),
        'ì €ìŠ¤íŠ¸ ê°€ë“œ ì„±ê³µ íšŸìˆ˜': stats.get('ì €ìŠ¤íŠ¸ ê°€ë“œ ì„±ê³µ íšŸìˆ˜', 'ë¯¸ì¸ì‹'),
        'ë°°í‹€ ì•„ì´í…œ ì‚¬ìš© íšŸìˆ˜': stats.get('ë°°í‹€ ì•„ì´í…œ ì‚¬ìš© íšŸìˆ˜', 'ë¯¸ì¸ì‹'),
        'ì§€ë‹¹íƒ€ ììƒ ê°ì†Œ ê°€ë™ë¥ ': stats.get('ì§€ë‹¹íƒ€ ììƒ ê°ì†Œ ê°€ë™ë¥ ', 'ë¯¸ì¸ì‹'),
        'êµ¬ìŠ¬ì˜ ì¶•ë³µ ìœ íš¨ìœ¨': stats.get('êµ¬ìŠ¬ì˜ ì¶•ë³µ ìœ íš¨ìœ¨', 'ë¯¸ì¸ì‹')
    }
    
    # HTML í…Œì´ë¸” ìƒì„±
    html_output = []
    html_output.append('<div class="lostark-stats-table">')
    html_output.append('<h3 style="color: #2c3e50; margin-bottom: 20px;">ğŸ¹ ë¡œìŠ¤íŠ¸ì•„í¬ ê¸¸ë“œ í†µê³„ ë¶„ì„ ê²°ê³¼</h3>')
    
    # ì£¼ìš” ì •ë³´ í…Œì´ë¸”
    html_output.append('<div class="main-stats">')
    html_output.append('<h4 style="color: #3498db; margin-bottom: 15px;">ğŸ“Š ì£¼ìš” ì •ë³´</h4>')
    html_output.append('<table style="width: 100%; border-collapse: collapse; margin-bottom: 25px;">')
    html_output.append('<thead><tr style="background-color: #3498db; color: white;"><th style="padding: 12px; text-align: left; border: 1px solid #ddd;">í•­ëª©</th><th style="padding: 12px; text-align: left; border: 1px solid #ddd;">ê°’</th></tr></thead>')
    html_output.append('<tbody>')
    
    for key, value in main_info.items():
        status_class = 'recognized' if value != 'ë¯¸ì¸ì‹' else 'not-recognized'
        html_output.append(f'<tr><td style="padding: 10px; border: 1px solid #ddd; font-weight: bold;">{key}</td><td style="padding: 10px; border: 1px solid #ddd;" class="{status_class}">{value}</td></tr>')
    
    html_output.append('</tbody></table>')
    html_output.append('</div>')
    
    # ì¶”ê°€ ì •ë³´ í…Œì´ë¸” (ì¸ì‹ëœ ê²ƒë§Œ)
    recognized_additional = {k: v for k, v in additional_info.items() if v != 'ë¯¸ì¸ì‹'}
    if recognized_additional:
        html_output.append('<div class="additional-stats">')
        html_output.append('<h4 style="color: #27ae60; margin-bottom: 15px;">ğŸ“ˆ ì¶”ê°€ ì •ë³´</h4>')
        html_output.append('<table style="width: 100%; border-collapse: collapse; margin-bottom: 25px;">')
        html_output.append('<thead><tr style="background-color: #27ae60; color: white;"><th style="padding: 12px; text-align: left; border: 1px solid #ddd;">í•­ëª©</th><th style="padding: 12px; text-align: left; border: 1px solid #ddd;">ê°’</th></tr></thead>')
        html_output.append('<tbody>')
        
        for key, value in recognized_additional.items():
            html_output.append(f'<tr><td style="padding: 10px; border: 1px solid #ddd; font-weight: bold;">{key}</td><td style="padding: 10px; border: 1px solid #ddd;" class="recognized">{value}</td></tr>')
        
        html_output.append('</tbody></table>')
        html_output.append('</div>')
    
    # ê³ ì‹ ë¢°ë„ í…ìŠ¤íŠ¸ (ë””ë²„ê¹…ìš©)
    if parsed_data.get('high_confidence_text'):
        html_output.append('<div class="debug-info" style="margin-top: 20px; padding: 15px; background-color: #f8f9fa; border-radius: 8px; border-left: 4px solid #17a2b8;">')
        html_output.append('<h5 style="color: #17a2b8; margin-bottom: 10px;">ğŸ” ê³ ì‹ ë¢°ë„ ì¸ì‹ í…ìŠ¤íŠ¸</h5>')
        html_output.append('<ul style="margin: 0; padding-left: 20px;">')
        for text in parsed_data['high_confidence_text'][:10]:
            html_output.append(f'<li style="margin: 5px 0; color: #495057;">{text}</li>')
        html_output.append('</ul>')
        html_output.append('</div>')
    
    html_output.append('</div>')
    
    # CSS ìŠ¤íƒ€ì¼ ì¶”ê°€
    style = """
    <style>
    .lostark-stats-table .recognized { color: #27ae60; font-weight: bold; }
    .lostark-stats-table .not-recognized { color: #e74c3c; font-style: italic; }
    .lostark-stats-table table { box-shadow: 0 2px 8px rgba(0,0,0,0.1); }
    .lostark-stats-table th { font-weight: bold; }
    .lostark-stats-table tr:nth-child(even) { background-color: #f8f9fa; }
    .lostark-stats-table tr:hover { background-color: #e3f2fd; }
    </style>
    """
    
    return style + "\n".join(html_output)

def main():
    if len(sys.argv) != 2:
        print(json.dumps({"error": "ì‚¬ìš©ë²•: python ocr_script.py <ì´ë¯¸ì§€_ê²½ë¡œ>"}))
        sys.exit(1)
    
    image_path = sys.argv[1]
    
    try:
        # PaddleOCR ë¦¬ë” ì´ˆê¸°í™” (í•œê¸€, ì˜ì–´)
        reader = PaddleOCR(use_textline_orientation=True, lang='korean')
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        processed_image = preprocess_image(image_path)
        
        # OCR ìˆ˜í–‰ (ìµœì‹  PaddleOCR v3.x)
        results = reader.predict(processed_image)
        
        # PaddleOCR v3.x ê²°ê³¼ë¥¼ EasyOCR í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        converted_results = []
        
        try:
            if results and len(results) > 0:
                result = results[0]  # ì²« ë²ˆì§¸ ê²°ê³¼
                
                # ë””ë²„ê¹…: ê²°ê³¼ êµ¬ì¡° ì¶œë ¥
                print(f"DEBUG: PaddleOCR ê²°ê³¼ í‚¤ë“¤: {result.keys()}", file=sys.stderr)
                
                # í…ìŠ¤íŠ¸ì™€ ì‹ ë¢°ë„ ì¶”ì¶œ
                if 'rec_texts' in result and 'rec_scores' in result:
                    texts = result['rec_texts']
                    scores = result['rec_scores']
                    polys = result.get('rec_polys', [])
                    
                    print(f"DEBUG: í…ìŠ¤íŠ¸ ìˆ˜: {len(texts)}, ì ìˆ˜ ìˆ˜: {len(scores)}, í´ë¦¬ê³¤ ìˆ˜: {len(polys)}", file=sys.stderr)
                    
                    # ì•ˆì „í•œ zip ì²˜ë¦¬
                    for i in range(min(len(texts), len(scores))):
                        text = texts[i] if i < len(texts) else ""
                        score = scores[i] if i < len(scores) else 0.0
                        
                        # í´ë¦¬ê³¤ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
                        if i < len(polys) and polys[i] is not None:
                            poly = polys[i]
                            bbox = poly.tolist() if hasattr(poly, 'tolist') else poly
                        else:
                            # ê¸°ë³¸ bbox (ì¢Œìƒë‹¨ 0,0ì—ì„œ ì‹œì‘í•˜ëŠ” ê°€ìƒ ë°•ìŠ¤)
                            bbox = [[0, 0], [100, 0], [100, 30], [0, 30]]
                        
                        converted_results.append((bbox, text, score))
                        print(f"DEBUG: ì¶”ê°€ëœ í…ìŠ¤íŠ¸: '{text}', ì‹ ë¢°ë„: {score}", file=sys.stderr)
                        
        except Exception as e:
            print(f"DEBUG: PaddleOCR ê²°ê³¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}", file=sys.stderr)
            print(f"DEBUG: ê²°ê³¼ íƒ€ì…: {type(results)}", file=sys.stderr)
            if results:
                print(f"DEBUG: ì²« ë²ˆì§¸ ê²°ê³¼ íƒ€ì…: {type(results[0])}", file=sys.stderr)
        
        results = converted_results
        
        # ë¡œìŠ¤íŠ¸ì•„í¬ ë°ì´í„° íŒŒì‹±
        parsed_data = parse_lostark_data(results)
        
        # ì›¹ìš© JSON ì¶œë ¥ (í‘œ ë°ì´í„° í¬í•¨)
        result_data = {
            "success": True,
            "table_html": format_as_table_html(parsed_data),
            "parsed_stats": parsed_data.get('parsed_stats', {}),
            "raw_data": parsed_data
        }
        print(json.dumps(result_data, ensure_ascii=False, indent=2))
        
    except Exception as e:
        import traceback
        error_data = {
            "success": False,
            "error": f"OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
            "error_type": type(e).__name__,
            "traceback": traceback.format_exc(),
            "image_path": image_path
        }
        print(json.dumps(error_data, ensure_ascii=False))
        sys.exit(1)

if __name__ == "__main__":
    main()